{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Intro to `pandas`\n", "\n", "We'll explore the Pandas package for simple data handling tasks using geoscience data examples. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Data management for machine learning\n", "- DataFrames: A new way to look at well logs.\n", "- DataFrames vs arrays.\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Basic Pandas"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Introduces the concept of a `DataFrame` in Python. If you're familiar with R, it's pretty much the same idea! Useful cheat sheet [here](https://www.datacamp.com/community/blog/pandas-cheat-sheet-python#gs.59HV6BY)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The main purpose of Pandas is to allow easy manipulation of data in tabular form. Perhaps the most important idea that makes Pandas great for data science, is that it will always preserve **alignment** between data and labels."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The most common data structure in Pandas is the `DataFrame`. A 2D structure that can hold various types of Python objects indexed by an `index` array (or multiple `index` arrays). Columns are usually labelled as well using strings.\n", "\n", "An easy way to think about a `DataFrame` is if you imagine it as an Excel spreadsheet.\n", "\n", "Let's define one using a numpy array:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["arr =  [[2.13, 'sandstone'],\n", "        [3.45, 'limestone'],\n", "        [2.45, 'shale']]\n", "arr"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Make a `DataFrame` from `arr`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.DataFrame(arr, columns=['velocity', 'lithology'])\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Accessing the data is a bit more complex than in the numpy array cases but for good reasons"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[df['velocity'] < 3, 'lithology']\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adding data\n", "\n", "Add more data (row wise)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[3] = [2.6, 'shale']\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add data (column wise) specifying the index locations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0:2, 'one_more_column'] = [6, 7, 8]\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Add a new column with a \"complete\" list, array or series"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['second_new_column'] = [\"x\", \"y\", \"z\", \"a\"]\n", "df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Reading a CSV"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pandas also reads files from disk in tabular form ([here](http://pandas.pydata.org/pandas-docs/version/0.20/io.html)'s a list of all the formats that it can read and write). A very common one is CSV, so let's load one!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"../data/2016_ML_contest_training_data.csv\")\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {"tags": ["exe"]}, "source": ["<div class=\"alert alert-success\">\n", "Create a new column called \"ILD\" and store in it the value of 10 to the power of the values in column \"ILD_log10\".\n", "\n", "Check the Pandas documentation [here](http://pandas.pydata.org/pandas-docs/version/0.22/api.html#data-manipulations) and look for a way to determine how many different facies are part of the `DataFrame`.", "\n</div>"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.groupby('Facies').size()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Inspecting the `DataFrame`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Using the `DataFrame` with well log information loaded before, we can make a summary using the `describe()` method of the `DataFrame` object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = df.dropna()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Adding more data to the `DataFrame`\n", "\n", "We'd like to augment the DataFrame with some new data, based on some of the existing data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_phi_rhob(phind, deltaphi):\n", "    \"\"\"\n", "    Compute phi_RHOB from phi_ND and Delta_phi.\n", "    \"\"\"\n", "    return 2 * (phind/100) / (1 - deltaphi/100) - deltaphi/100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def calc_rhob(phi_rhob, rho_matrix=2650.0, rho_fluid=1000.0):\n", "    \"\"\"\n", "    Returns density porosity log.\n", "    \n", "    Some typical values for rho_matrix:\n", "      Sandstone:  2650 kg/m^3\n", "      Limestone:  2710 kg/m^3\n", "      Dolomite:   2880 kg/m^3\n", "      Anyhydrite: 2980 kg/m^3\n", "      Salt:       2030 kg/m^3\n", "\n", "    Some typical values for rho_fluid:\n", "      Fresh water: 1000 kg/m^3\n", "      Salt water:  1100 kg/m^3\n", "      Heavy oil:   1000 kg/m^3\n", "      Light oil:    800 kg/m^3\n", "      LNG:          650 kg/m^3\n", "    \n", "    See wiki.aapg.org/Density-neutron_log_porosity\n", "    \"\"\"\n", "    return rho_matrix * (1 - phi_rhob) + rho_fluid * phi_rhob"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["phi_rhob = calc_phi_rhob(df.PHIND, df.DeltaPHI)\n", "df['RHOB'] = calc_rhob(phi_rhob)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can define a Python dictionary to relate facies with the integer label on the `DataFrame`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["facies_dict = {1:'sandstone', 2:'c_siltstone', 3:'f_siltstone', 4:'marine_silt_shale',\n", "               5:'mudstone', 6:'wackestone', 7:'dolomite', 8:'packstone', 9:'bafflestone'}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's add a new column with the name version of the facies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"s_Facies\"] = [facies_dict.get(x, \"Unknown\") for x in df.Facies]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There is also a `replace` method on DataFrames and Series, and it takes a dictionary for what to replace with what. So we could also achieve the same thing by passing our dictionary to that."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"s_Facies\"] = df[\"Facies\"].replace(facies_dict)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If the key is not in the dict, then it is not replaced and the original key is used instead:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0:2, 'Facies'] = 99"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[\"s_Facies\"] = df[\"Facies\"].replace(facies_dict)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head(10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0:2, 'Facies'] = 3\n", "df[\"s_Facies\"] = df[\"Facies\"].replace(facies_dict)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head(10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Visual exploration of the data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can easily visualize the properties of each facies and how they compare using a `PairPlot`. The library `seaborn` integrates with matplotlib to make these kind of plots easily."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.pairplot(df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.pairplot(df,\n", "             hue=\"s_Facies\",\n", "             vars=['GR','RHOB','PE','ILD_log10'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can have a lot of control over all of the elements in the pair-plot by using the `PairGrid` object."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "g = sns.PairGrid(df, hue=\"s_Facies\", vars=['GR','RHOB','PE','ILD_log10'], size=4)\n", "\n", "g.map_upper(plt.scatter,**dict(alpha=0.4))  \n", "g.map_lower(plt.scatter,**dict(alpha=0.4))\n", "g.map_diag(plt.hist,**dict(bins=20))  \n", "g.add_legend()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is very clear that it's hard to separate these facies in feature space. Let's just select a couple of facies and using Pandas, select the rows in the `DataFrame` that contain information about those facies "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["selected = ['f_siltstone', 'bafflestone', 'wackestone']\n", "\n", "dfs = pd.concat([df[df.s_Facies == x] for x in selected])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["g = sns.PairGrid(dfs, hue=\"s_Facies\", vars=['GR','RHOB','PE','ILD_log10'], size=4)  \n", "g.map_upper(plt.scatter, alpha=0.4)\n", "g.map_lower(plt.scatter, alpha=0.4)\n", "g.map_diag(plt.hist,**dict(bins=20))  \n", "g.add_legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfs = dfs.sort_values(['Well Name', 'Depth'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfs.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfs.to_csv(\"../data/training_DataFrame_processed.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---\n", "\n", "**INTRO TO GEOCOMPUTING STUDENTS STOP HERE**\n", "\n", "---\n", "\n", "## Exploring data beyond Matplotlib\n", "\n", "A few other plotting libraries have emerged with the rise in popularity of data science that make use of JavaScript to add interactivity. Examples:\n", " - [Altair](https://altair-viz.github.io/index.html)\n", " - [Holoviews](http://holoviews.org/index.html)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Altair\n", "To install, activate `geocomp` and type:\n", "- `pip install -U altair vega_datasets notebook vega`\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import altair as alt\n", "alt.renderers.enable('notebook')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import altair as alt\n", "\n", "xscale = alt.Scale(domain=(0, 350.0))\n", "yscale = alt.Scale(domain=(0, 35))\n", "\n", "area_args = {'opacity': .5, 'interpolate': 'step'}\n", "blank_axis = alt.Axis(title='')\n", "\n", "points = alt.Chart(dfs).mark_circle().encode(\n", "    alt.X('GR', scale=xscale),\n", "    alt.Y('ILD', scale=yscale),\n", "    color='s_Facies',\n", ")\n", "\n", "top_hist = alt.Chart(dfs).mark_area(**area_args).encode(\n", "    alt.X('GR:Q',\n", "          # when using bins, the axis scale is set through\n", "          # the bin extent, so we do not specify the scale here\n", "          # (which would be ignored anyway)\n", "          bin=alt.Bin(maxbins=20, extent=xscale.domain),\n", "          stack=None,\n", "          axis=blank_axis,\n", "         ),\n", "    alt.Y('count()', stack=None, axis=blank_axis),\n", "    alt.Color('s_Facies:N'),\n", ").properties(height=60)\n", "\n", "right_hist = alt.Chart(dfs).mark_area(**area_args).encode(\n", "    alt.Y('ILD:Q',\n", "          bin=alt.Bin(maxbins=20, extent=yscale.domain),\n", "          stack=None,\n", "          axis=blank_axis,\n", "         ),\n", "    alt.X('count()', stack=None, axis=blank_axis),\n", "    alt.Color('s_Facies:N'),\n", ").properties(width=60)\n", "\n", "top_hist & (points | right_hist)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["brush = alt.selection_interval(encodings=['x'])\n", "color = alt.Color('s_Facies:N')\n", "xscale = alt.Scale(domain=(0, 350.0))\n", "yscale = alt.Scale(domain=(1.9, 4.55))\n", "\n", "area_args = {'opacity': .5, 'interpolate': 'step'}\n", "blank_axis = alt.Axis(title='')\n", "\n", "c1 = alt.Chart(dfs).mark_circle(opacity=.5).encode(\n", "    alt.X('GR', type='quantitative'),\n", "    alt.Y('RHOB', type='quantitative'),\n", "    color=alt.condition(brush, color, alt.value('lightgray')),\n", ").add_selection(brush)\n", "\n", "c2 = alt.Chart(dfs).mark_circle(opacity=.5).encode(\n", "    alt.X('GR', type='quantitative'),\n", "    alt.Y('ILD', type='quantitative'),\n", "    color=alt.condition(brush, color, alt.value('lightgray')),\n", ").add_selection(brush)\n", "\n", "top_hist = alt.Chart(dfs).mark_area(**area_args).encode(\n", "    alt.X('GR:Q',\n", "          bin=alt.Bin(maxbins=30, extent=xscale.domain),\n", "          stack=None,\n", "          axis=blank_axis,\n", "         ),\n", "    alt.Y('count()', stack=None, axis=blank_axis),\n", "    alt.Color('s_Facies:N'),\n", ").transform_filter(brush).properties(height=60)\n", "\n", "top_hist & c1 & c2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Holoviews\n", "\n", "To install, activate `geocomp` and type:\n", "- `pip install \"holoviews[recommended]\"`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import holoviews as hv\n", "hv.extension('bokeh')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from holoviews.operation import gridmatrix\n", "\n", "ds = hv.Dataset(dfs[['GR','RHOB','PE','ILD_log10','s_Facies']])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%opts Bivariate [bandwidth=0.5] (cmap=Cycle(values=['Blues', 'Reds', 'Oranges'])) Points (size=2 alpha=0.5)\n", "\n", "grouped_by_facies = ds.groupby('s_Facies', container_type=hv.NdOverlay)\n", "density_grid = gridmatrix(grouped_by_facies, diagonal_type=hv.Distribution, chart_type=hv.Bivariate)\n", "point_grid = gridmatrix(grouped_by_facies, chart_type=hv.Points)\n", "\n", "density_grid * point_grid"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<hr />\n", "\n", "<p style=\"color:gray\">\u00a92017 Agile Geoscience. Licensed CC-BY.</p>"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "geocomp", "language": "python", "name": "geocomp"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}